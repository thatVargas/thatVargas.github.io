---
layout: post
title: "Social Media - The world through a rectangle"
---
<span style="display:block;text-align:center">![ Image stylyized to look pixelated of two hands holding up smart phone up to each other so that the screens are toucing.](/images/phones-interacting.jpg "Credit:https://pxhere.com/en/photo/1086926")</span>

## Definition?

> Definition of social media from Merriam-Webster: forms of electronic communication - such as websites for social networking and microblogging - through which users create online communities to share information, ideas, personal messages, and other content - such as videos.
> First Known Use: 2004


## Knowledge and Power

There is an interesting argument arising in the platform-zero space (such as wikipedia zero) where, in the interest of providing a subset of access to the internet for all, we are actually limiting the sources of information that these emerging markets may have access to. In countries where platform-zero access is in place, not only are we limiting the diversity of content that they have access to, but also the formats that they are presented in.
  
If the creation of knowledge is foundational, then does limiting the access to its raw materials, create frameworks that are less stable and sustainable in the future? Especially given that we seem to be generating data at an almost pandemic rate.
  
Tangentially, In “ An Open-Source Strategy for Documenting Events: The Case Study of the 42nd Canadian Federal Election on Twitter”, the author writes, “ IBM Research, for example, notes that, “every day, we create 2.5 quintillion bytes of data — so much that 90% of the data in the world today has been created in the last two years alone.” However, one must be careful to not confuse data with knowledge. How much of this statistic represents production of knowledge, not just data? Does this kind of interpretation of production lead us to think that we are creating knowledge, or somehow bias us in to thinking that the old 10% of knowledge is perhaps less valid than the new 90%? I wonder.

## Propaganda and Discourse

In the context of propaganda, Shaffer writes that “In its oldest context, it simple[sic] refers to the spreading of a message, whether through word of mouth, or through print media.“ But is what is going in social media really new, or has technology simply enable a change in scale? has the meaning stayed pretty much the same, but with a change in the scale and medium? I.e. we are now doing this with self propaganda and online as a medium? Which means that we may see the importance of individual messages in that medium with the same importance as those of media outlets? Has social media reduced the contrasts in the social hierarchy, thus making it more difficult for us to discern differences?
  
What is even more frightening is that in the US, the "stable genius" tweets from his own account, essentially making himself as an individual the voice of his administration, as opposed to the political office of the president. Not only does this impact the present, but it can also undermine political power and influence of official social media accounts in the future. This kind of behaviour can also reinforce the notion that one gains social capital from “going it alone”, which may also impact social cohesion in organizations and institutions that require it in order to be able to effectively carry out their mandates.
  
While I liked most of what “10 ways to get started fighting internet propaganda“ had to offer, I can't help but feel that it is very left biased. I wish it had more of an altruistic path, interested in truth for the sake of truth, rather than one truth in opposition to another truth. The left pooched itself in the last US presidential election with this kind of mindset and that's largely how we ended up with the "stable genius" in power. I would like to see a discourse that encourages discussion from all sides and allows people to agree to disagree on facts, rather than feel like they need to continually defend opinions.

## Relationships and Algorithms

In “Breaking up with Facebook”, Estee writes about the algorithms that seem to be trying to hack our relationships by limiting what we see in our feeds. But I see this in a different light. Are these agents trying to mold our behaviour or are they modelling it? I.e. Are they trying to approximate what we do, or trying to change who we are?
  
What if the algorithms are trying to mimic what we do in the real world. Keeping in mind that relationships online are not necessarily of the same calibre as those in the real world, if the algorithm was to do what the author suggests it would (not limit your focus based on interests) then wouldn't that be in fact more nefarious than the way it works now, because it would be presenting things to you that may go against what you want?
  
Estee writes, “ This means the more a user comments or views another person’s posts or page, the more that person’s posts will appear in the user’s newsfeed.” But is this not somewhat like how the Google algorithm was rumoured to work, in that the strength of a search result was based on how many other articles or results linked to it? So, in a way, it sounds like at the time time the article was written, FB was basing what you saw in your feed on the strength of your relationships. I.e. if you showed a keen interest in one person's feed, then it would show you more of that. While I see the author's point, isn't that how things work in real life as well? I mean, don't we use a similar way to focus our attentions on friends and acquaintances in real life, where those we are most interested in will at the forefront of our consciousness?
  
We seem to be in an interesting liminal state with technology, in which the scale is too big to make it worthwhile to pay humans to deal with the monetization of all the content on platforms such as social media, yet the algorithms are not yet rich enough to understand all the nuances and complexities that arise as a result of human interaction. This is also interesting because it makes it difficult to assign responsibility for things that we may not have thought of yet, that only arise once a situation happens. In this case, it would seem that what is more important is how quickly the owners of that algorithm react to rectify the situation, rather than whether they just didn't catch a certain use case.

## Media Literacy and Privacy

In a very connected world, it I important to teach people (young and old) about what it means to be part of a digital ecosystem by teaching media literacy. This kind of preparation would work wonders in terms of informing students about the relationships between products and producers in the information/knowledge economy.
  
At the same time, it is important to maintain the discourse on who has access to and owns the data that we produce, whether actively (through intentional production) or passively (through the trail we leave as we move through the digital landscape). This raises issues as it relates to privacy, especially in in the age of the Internet of Things, where more and more passive components of our lives have the capability of becoming listening posts. Especially as connectivity of devices becomes increasingly embedded and the fact that an object may be able to do more than what its affordances would suggest becomes easily missed or overlooked. The issue to whether a device such as Amazon’s Alexa or Google’s Home could become passive [witnesses in the case of criminal activity]( bloomberg.com/news/articles/2016-12-28/alexa-a-witness-to-murder-prosecutors-seek-amazon-echo-data), will make for interesting precedents to be set about privacy in the future.
  
In the case of “ An Open-Source Strategy for Documenting Events: The Case Study of the 42nd Canadian Federal Election on Twitter”, it gives rise to an interesting tension between the need to capture data for historical purposes, and privacy issues that may interfere with that. How fine is the line between public good and invasion of privacy? The issue is further muddied in today's conflict landscape, where there are seemingly no rules that extreme factions are willing to abide by. It leads one to wonder if this is the new reality in terms of privacy, in which content that we publish to social media platforms, whether to a closed audience or mass audience, just becomes part of public record, along with any ancillary data that goes along with it, such as location, etc. Is there a way back from this, or is that just the way it is now?
  
It is worrying that a social media platform has become a historical source for an event of this magnitude, given the dark hat tactics that have been brought up in other readings. It will be very important to ensure that we track interpretations and biases along with the data, as one of the issues with big data is in how it gets interpreted. I find it wonderful, however, that social media will be able to represent the voices of so many people, and am excited by future technologies and their capabilities to perform types of text analysis that we have not even thought of today.

## What Next?

While I agree with the notions of making sure that we become literate in our approach to technology and knowledge of the digital footprints we leave behind, we need to be careful to consider the full complexity of the impacts of social media and how this will help or hinder the relationships at different scales of the socio-cultural landscape, especially in the face of an ever-increasing population and increasing conflicts over resources and identities. These may well require an adaptation in our expectations of things such as privacy at certain levels towards notions of a "greater good". But that will bring with it, its own set complexities. Looks like we'll have our work cut out for us, as we relate to the world through our rectangles.

